# URP Full Stack - Docker Compose
# ================================
# Run complete URP infrastructure:
#   docker compose up -d memgraph
#   docker compose run --rm master
#
# Or use urp CLI for more control:
#   urp infra start
#   urp launch

networks:
  urp:
    name: urp-network
    driver: bridge

volumes:
  memgraph-data:
    name: urp-memgraph-data
  urp-vectors:
    name: urp-vectors

services:
  # ═══════════════════════════════════════════════════════════════
  # Memgraph - Graph Database
  # ═══════════════════════════════════════════════════════════════
  memgraph:
    build:
      context: .
      dockerfile: docker/Dockerfile.memgraph
    image: urp:memgraph
    container_name: urp-memgraph
    restart: unless-stopped
    networks:
      - urp
    ports:
      - "7687:7687"   # Bolt protocol
      - "7444:7444"   # Web interface (optional)
    volumes:
      - memgraph-data:/var/lib/memgraph
    environment:
      - MEMGRAPH_ENTERPRISE_LICENSE=
      - MEMGRAPH_ORGANIZATION_NAME=
    healthcheck:
      test: ["CMD-SHELL", "echo 'RETURN 1;' | mgconsole > /dev/null || exit 1"]
      interval: 10s
      timeout: 10s
      retries: 5
      start_period: 20s

  # ═══════════════════════════════════════════════════════════════
  # Text Embeddings Inference (Sovereign Embeddings)
  # ═══════════════════════════════════════════════════════════════
  tei:
    image: ghcr.io/huggingface/text-embeddings-inference:cpu-1.5
    container_name: urp-tei
    restart: unless-stopped
    networks:
      - urp
    ports:
      - "8080:80" # Expose for debugging/local testing
    volumes:
      - urp-vectors:/data # Cache models here
    environment:
      - PORT=80
      # BAAI/bge-small-en-v1.5: 384 dims, no auth required, fast
      # Alternative: sentence-transformers/all-MiniLM-L6-v2 (384 dims)
      - MODEL_ID=${TEI_MODEL:-BAAI/bge-small-en-v1.5}
    command: --model-id ${TEI_MODEL:-BAAI/bge-small-en-v1.5} --port 80 --huggingface-hub-cache /data
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:80/health"]
      interval: 30s
      timeout: 10s
      retries: 5
      start_period: 60s # Model download takes time

  # ═══════════════════════════════════════════════════════════════
  # Master - Claude + Full Tools (OpenAI-compatible API)
  # ═══════════════════════════════════════════════════════════════
  master:
    build:
      context: .
      target: master
    image: urp:master
    container_name: urp-master
    networks:
      - urp
    depends_on:
      memgraph:
        condition: service_healthy
    volumes:
      - ./:/workspace:cached
      - urp-vectors:/var/lib/urp/vector
      - ${HOME}/.config/claude:/home/urp/.config/claude:ro
      - ${HOME}/.gitconfig:/home/urp/.gitconfig:ro
    environment:
      - NEO4J_URI=bolt://urp-memgraph:7687
      - URP_PROJECT=${URP_PROJECT:-unknown}
      # Anthropic API (Claude Code) - without /v1
      - ANTHROPIC_API_KEY=${ANTHROPIC_API_KEY:-NOHACEFALTA-NOHACEFALTA}
      - ANTHROPIC_BASE_URL=${ANTHROPIC_BASE_URL:-http://100.105.212.98:8317}
      # OpenAI-compatible API (for other tools)
      - OPENAI_API_KEY=${OPENAI_API_KEY:-NOHACEFALTA-NOHACEFALTA}
      - OPENAI_BASE_URL=${OPENAI_BASE_URL:-http://100.105.212.98:8317/v1}
      # Sovereign Embeddings: use local TEI service
      - URP_EMBEDDING_PROVIDER=tei
      - TEI_URL=http://urp-tei:80
      # GitHub for PRs
      - GH_TOKEN=${GH_TOKEN:-}
      - GITHUB_TOKEN=${GH_TOKEN:-}
    stdin_open: true
    tty: true

  # ═══════════════════════════════════════════════════════════════
  # Worker - Dev Tools + Protocol
  # ═══════════════════════════════════════════════════════════════
  worker:
    build:
      context: .
      target: worker
    image: urp:worker
    networks:
      - urp
    depends_on:
      memgraph:
        condition: service_healthy
    volumes:
      - ./:/workspace
      - urp-vectors:/var/lib/urp/vector
      - ${HOME}/.gitconfig:/home/urp/.gitconfig:ro
    environment:
      - NEO4J_URI=bolt://urp-memgraph:7687
      - URP_PROJECT=${URP_PROJECT:-unknown}
      - URP_WORKER_ID=${URP_WORKER_ID:-worker-1}
      - GH_TOKEN=${GH_TOKEN:-}
      - GITHUB_TOKEN=${GH_TOKEN:-}
    stdin_open: true
    tty: true

  # ═══════════════════════════════════════════════════════════════
  # OpenCode Master - New Orchestrator (Parallel Evolution)
  # ═══════════════════════════════════════════════════════════════
  opencode-master:
    build:
      context: .
      target: master
    image: urp:master
    container_name: urp-opencode-master
    networks:
      - urp
    depends_on:
      memgraph:
        condition: service_healthy
    volumes:
      - ./:/workspace:cached
      - urp-vectors:/var/lib/urp/vector
      - ${HOME}/.config/claude:/home/urp/.config/claude:ro
      - ${HOME}/.gitconfig:/home/urp/.gitconfig:ro
    environment:
      - NEO4J_URI=bolt://urp-memgraph:7687
      - URP_PROJECT=${URP_PROJECT:-unknown}
      - URP_MODE=opencode
      - ANTHROPIC_API_KEY=${ANTHROPIC_API_KEY:-NOHACEFALTA-NOHACEFALTA}
      - ANTHROPIC_BASE_URL=${ANTHROPIC_BASE_URL:-http://100.105.212.98:8317}
      - OPENAI_API_KEY=${OPENAI_API_KEY:-NOHACEFALTA-NOHACEFALTA}
      - OPENAI_BASE_URL=${OPENAI_BASE_URL:-http://100.105.212.98:8317/v1}
      # Sovereign Embeddings: use local TEI service
      - URP_EMBEDDING_PROVIDER=tei
      - TEI_URL=http://urp-tei:80
      - GH_TOKEN=${GH_TOKEN:-}
      - GITHUB_TOKEN=${GH_TOKEN:-}
    stdin_open: true
    tty: true

  # ═══════════════════════════════════════════════════════════════
  # OpenCode Worker - New Executor (Parallel Evolution)
  # ═══════════════════════════════════════════════════════════════
  opencode-worker:
    build:
      context: .
      target: worker
    image: urp:worker
    container_name: urp-opencode-worker
    networks:
      - urp
    depends_on:
      memgraph:
        condition: service_healthy
    volumes:
      - ./:/workspace
      - urp-vectors:/var/lib/urp/vector
      - ${HOME}/.gitconfig:/home/urp/.gitconfig:ro
    environment:
      - NEO4J_URI=bolt://urp-memgraph:7687
      - URP_PROJECT=${URP_PROJECT:-unknown}
      - URP_WORKER_ID=opencode-worker-1
      - URP_MODE=opencode
      - GH_TOKEN=${GH_TOKEN:-}
      - GITHUB_TOKEN=${GH_TOKEN:-}
    stdin_open: true
    tty: true

  # ═══════════════════════════════════════════════════════════════
  # Dev - Full image for development (no Claude)
  # ═══════════════════════════════════════════════════════════════
  dev:
    build:
      context: .
      target: full
    image: urp:full
    networks:
      - urp
    depends_on:
      memgraph:
        condition: service_healthy
    volumes:
      - ./:/workspace
      - urp-vectors:/var/lib/urp/vector
    environment:
      - NEO4J_URI=bolt://urp-memgraph:7687
      - URP_PROJECT=${URP_PROJECT:-unknown}
    stdin_open: true
    tty: true
    profiles:
      - dev  # Only start with: docker compose --profile dev up

  # ═══════════════════════════════════════════════════════════════
  # Minimal - Just URP CLI (no shell)
  # ═══════════════════════════════════════════════════════════════
  cli:
    build:
      context: .
      target: minimal
    image: urp:minimal
    networks:
      - urp
    depends_on:
      memgraph:
        condition: service_healthy
    volumes:
      - ./:/workspace:ro
    environment:
      - NEO4J_URI=bolt://urp-memgraph:7687
    profiles:
      - cli  # Only with: docker compose --profile cli run cli
